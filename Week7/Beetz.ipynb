{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2504857",
   "metadata": {},
   "source": [
    "# Music Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e10f361d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tools\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ae9f36",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "345af5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "# displays exit message\n",
    "def say_goodbye():\n",
    "    print('Thanks for using BEETz! Come back soon!')\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "# checks for last scrape by reading txt file in which last date was stored\n",
    "def check_last_scrape():\n",
    "    with open('last_scrape.txt', 'r') as f:\n",
    "        date = f.read()\n",
    "    return date\n",
    "        \n",
    "    \n",
    "    \n",
    "# random excitement\n",
    "def exclaim():\n",
    "    exclamations=['SOO hot right now!', 'So hot its stolen!', 'Sizzzzzling!']\n",
    "    exclamation = random.choice(exclamations)\n",
    "    print('\\n', exclamation)\n",
    "\n",
    "    \n",
    "    \n",
    "# scrapes songs from online billboard, writes to csv, returns as df and records timestamp in txt file\n",
    "def fetch_hot_songs():\n",
    "    print('Fetching hot songs and artists from the web...')\n",
    "    \n",
    "    url = \"https://www.billboard.com/charts/hot-100/\"\n",
    "    response = requests.get(url)\n",
    "    website_data = response.text\n",
    "    soup = BeautifulSoup(website_data, \"html.parser\")\n",
    "    \n",
    "    # append songs and artists to lists\n",
    "    songs = []\n",
    "    artists = []\n",
    "    for i in tqdm(range(100)):\n",
    "        songs.append(soup.select('h3.c-title.a-no-trucate')[i].get_text(strip=True))\n",
    "        artists.append(soup.select('span.c-label.a-no-trucate')[i].get_text(strip=True))\n",
    "    \n",
    "    # write to DataFrame\n",
    "    df_dirty = pd.DataFrame({'songs':songs, 'artists':artists})\n",
    "    df.to_csv('TopSongs.csv', index=False) \n",
    "    \n",
    "    # write timestamp to txt file\n",
    "    timestamp= datetime.today().strftime('%Y-%m-%d')\n",
    "    with open('last_scrape.txt', 'w') as f:\n",
    "        f.write(timestamp)\n",
    "            \n",
    "    print('Fetch completed!\\n')\n",
    "    return df\n",
    "    \n",
    "    \n",
    "    \n",
    "# gets random song from scraped billboard and checks if identical with requested song\n",
    "def get_random_song(x, df):\n",
    "    # takes sample from unclean dataframe\n",
    "    sample = df.sample()\n",
    "    rec_song = str(sample.iloc[0, 0])\n",
    "    rec_artist = str(sample.iloc[0, 1])\n",
    "    # clean song and check to make sure its not the same song as requested\n",
    "    lower_song = rec_song.lower()\n",
    "    song_cleaned = ''.join(e for e in lower_song if e.isalnum())\n",
    "    if x in song_cleaned:\n",
    "        get_random_song(x, df_clean, df)\n",
    "    else:\n",
    "        print(f'BEETz recommends {rec_song} by {rec_artist}!')\n",
    "        print('Go again?')\n",
    "    \n",
    "        \n",
    "\n",
    "        \n",
    "# Based on run_search, asks user to enter song, formats and checks to see if song is in 'hot' songs\n",
    "def song_search(df_clean, df):\n",
    "    song = input('Please enter the title of a song you enjoy: \\n').lower()\n",
    "    # remove spaces and special characters\n",
    "    song_cleaned = ''.join(e for e in song if e.isalnum())\n",
    "    \n",
    "    # check if song title is in top hits\n",
    "    if df_clean['songs'].str.contains(song_cleaned).any():\n",
    "        exclaim()\n",
    "        return song_cleaned\n",
    "    # if not, offer another search\n",
    "    else:\n",
    "        print('Your song doesn\\'t seem to be very popular...try again? ')\n",
    "        run_search(df_clean, df)\n",
    "            \n",
    "    \n",
    "    \n",
    "# Based on run_search, asks user to enter artist, formats and checks if artist is in 'hot' artists\n",
    "def artist_search(df_clean, df):\n",
    "    artist = input('Please enter the name of an artist you enjoy: \\n').lower()\n",
    "    # remove spaces and special characters\n",
    "    artist_cleaned = ''.join(e for e in artist if e.isalnum())\n",
    "    \n",
    "    # check if artist is in top artists\n",
    "    if df_clean['artists'].str.contains(artist_cleaned).any():\n",
    "        exclaim()\n",
    "        return '-'\n",
    "    # if not, offer another search\n",
    "    else:\n",
    "        print('Your artist doesn\\'t seem to be very popular...try again? ')\n",
    "        run_search(df_clean, df)\n",
    "            \n",
    "\n",
    "            \n",
    "# gets user search preference and executes search accordingly\n",
    "def run_search(df_clean, df):    \n",
    "    response = input('''\n",
    "    Enter 1 to search by song.\n",
    "    Enter 2 to search by artist. \n",
    "    Enter 3 to exit.\\n\\n''')  \n",
    "    if response == '1':\n",
    "        x = song_search(df_clean, df)\n",
    "    elif response == '2':\n",
    "        x = artist_search(df_clean, df)\n",
    "    elif response == '3':\n",
    "        say_goodbye()\n",
    "        return\n",
    "    else:\n",
    "        print('Hm...that didn\\'t work. Please try again.')\n",
    "        run_search(df_clean, df)\n",
    "    \n",
    "    # Recommends random song after checking that it doesn't match searched song\n",
    "    get_random_song(x, df)\n",
    "    \n",
    "    run_search(df_clean, df)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e652c0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the MOTHER function\n",
    "\n",
    "def beetz():\n",
    "    \n",
    "    print('''\n",
    "     ____  ______ ______ _______  \n",
    " |  _ \\|  ____|  ____|__   __| \n",
    " | |_) | |__  | |__     | |____\n",
    " |  _ <|  __| |  __|    | |_  /\n",
    " | |_) | |____| |____   | |/ / \n",
    " |____/|______|______|  |_/___|\n",
    " ''')\n",
    "        \n",
    "    print('HELLO! Welcome to the BEETz song recommender!')\n",
    "    print('BEETz will recommend a song related to the song or artist you enter.')\n",
    "    \n",
    "    \n",
    "    # checks for last scrape - if not from today, launches new scrape\n",
    "    if check_last_scrape() == datetime.today().strftime('%Y-%m-%d'):\n",
    "        print('We have an up-to-date list of HOT songs from today on file!')\n",
    "        df = pd.read_csv('TopSongs.csv', index_col=False)\n",
    "    else:\n",
    "        print('We will fetch an up-to-date list of HOT songs from today!')\n",
    "        df = fetch_hot_songs()\n",
    "    \n",
    "    # lowercase and remove special characters and spaces from df\n",
    "    df_lower = df.applymap(lambda s: s.lower() if type(s) == str else s)\n",
    "    formatter = lambda s: ''.join(e for e in s if e.isalnum())\n",
    "    df_clean = df_lower.applymap(formatter)\n",
    "    \n",
    "    # gets user search preference and executes search accordingly\n",
    "    x = run_search(df_clean, df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1501fcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     ____  ______ ______ _______  \n",
      " |  _ \\|  ____|  ____|__   __| \n",
      " | |_) | |__  | |__     | |____\n",
      " |  _ <|  __| |  __|    | |_  /\n",
      " | |_) | |____| |____   | |/ / \n",
      " |____/|______|______|  |_/___|\n",
      " \n",
      "HELLO! Welcome to the BEETz song recommender!\n",
      "BEETz will recommend a song related to the song or artist you enter.\n",
      "We have an up-to-date list of HOT songs from today on file!\n",
      "\n",
      "    Enter 1 to search by song.\n",
      "    Enter 2 to search by artist. \n",
      "    Enter 3 to exit.\n",
      "\n",
      "1\n",
      "Please enter the title of a song you enjoy: \n",
      "adele\n",
      "Your song doesn't seem to be very popular...try again? \n",
      "\n",
      "    Enter 1 to search by song.\n",
      "    Enter 2 to search by artist. \n",
      "    Enter 3 to exit.\n",
      "\n",
      "sfgsdf\n",
      "Hm...that didn't work. Please try again.\n",
      "\n",
      "    Enter 1 to search by song.\n",
      "    Enter 2 to search by artist. \n",
      "    Enter 3 to exit.\n",
      "\n",
      "2\n",
      "Please enter the name of an artist you enjoy: \n",
      "adele\n",
      "\n",
      " Sizzzzzling!\n",
      "BEETz recommends Thinking 'Bout You by Dustin Lynch Featuring Lauren Alaina Or MacKenzie Porter!\n"
     ]
    }
   ],
   "source": [
    "beetz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb264782",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('TopSongs.csv', index_col=False)\n",
    "\n",
    "# lowercase and remove special characters and spaces from df\n",
    "df_lower = df.applymap(lambda s: s.lower() if type(s) == str else s)\n",
    "formatter = lambda s: ''.join(e for e in s if e.isalnum())\n",
    "df_clean = df_lower.applymap(formatter)\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a07db3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27295af4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5297b5d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63d4cfbb",
   "metadata": {},
   "source": [
    "# Scrape songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5d2e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. find url and store it in avariable\n",
    "url = \"https://www.imdb.com/chart/top\"\n",
    "\n",
    "# 3. download html with a get request\n",
    "response = requests.get(url)\n",
    "\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42652328",
   "metadata": {},
   "source": [
    "## Get csv files from Shazam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0195dcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "\n",
    "testfile = urllib.URLopener()\n",
    "testfile.retrieve(\"https://www.shazam.com/services/charts/csv/top-200/world/\", \"file.csv\")\n",
    "df = pd.read_csv('file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb59808",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.shazam.com/services/charts/csv/top-200/world/'\n",
    "r = requests.get(url, allow_redirects=True)\n",
    "open('songs.csv', 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65591d14",
   "metadata": {},
   "source": [
    "## Scraping pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8e9b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f66b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "root_url = 'https://www.officialcharts.com/charts/'\n",
    "\n",
    "# put all relevant URL segments in list\n",
    "urls = ['singles-chart','afrobeats-chart']\n",
    "\n",
    "# Loop through URL\n",
    "for url in urls:\n",
    "    response = requests.get(f'https://www.officialcharts.com/charts/{url}/')\n",
    "    \n",
    "    # confirm response\n",
    "    print(response.status_code)\n",
    "    \n",
    "    # make soup\n",
    "    data = response.text\n",
    "    soup = BeautifulSoup(data, 'html.parser')\n",
    "    \n",
    "    # get artists and titles\n",
    "    titles = []\n",
    "    artists = []                        \n",
    "    for x in range(len(soup.select('.title'))):\n",
    "        titles.append(soup.select('.title')[x].get_text(strip=True))\n",
    "        artists.append(soup.select('.artist')[x].get_text(strip=True))\n",
    "    \n",
    "    # get artists\n",
    "    # artists = []\n",
    "    #for x in range(len(soup.select('.artist'))):\n",
    "     #   artists.append(soup.select('.artist')[x].get_text(strip=True))                        \n",
    "    \n",
    "    # convert to dataframe and add to dict\n",
    "    #df_dict ={}                     \n",
    "                            \n",
    "    df = pd.DataFrame({'artist':artists, 'title':titles})\n",
    "    # add column 'genre'\n",
    "    df['genre'] = url\n",
    "    \n",
    "    # add to dict\n",
    "    df.to_csv(f'{url}_list.csv')\n",
    "                                                      \n",
    "    sleep(4)\n",
    "\n",
    "#print(df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d687f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('singles_chart_list.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfbddc5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = response.text\n",
    "soup = BeautifulSoup(data, 'html.parser')\n",
    "# print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badfe9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.select('.title')[0].get_text(strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3268de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup.select('.title')\n",
    "titles = []\n",
    "for x in range(len(soup.select('.title'))):\n",
    "    titles.append(soup.select('.title')[x].get_text(strip=True))\n",
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3227ca0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221d8e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get artists\n",
    "artists = []\n",
    "for x in range(len(soup.select('.artist'))):\n",
    "    artists.append(soup.select('.artist')[x].get_text(strip=True))\n",
    "artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83bcde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(artists)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
